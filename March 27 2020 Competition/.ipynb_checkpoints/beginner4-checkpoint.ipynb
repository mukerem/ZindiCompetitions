{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "id": "GsxsCJyNFxBZ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import librariesmodel = RandomForestClassifier()\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import auc, classification_report, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "\n",
    "pd.set_option('max_colwidth', 500)\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "id": "0_7BVS92U0Ti"
   },
   "outputs": [],
   "source": [
    "# Load files\n",
    "train = pd.read_csv('Train.csv')\n",
    "test = pd.read_csv('Test.csv')\n",
    "samplesubmission = pd.read_csv('SampleSubmission.csv')\n",
    "variable_definations = pd.read_csv('VariableDefinitions.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = max(train['population'])\n",
    "# for i in range(train.shape[0]):\n",
    "#     train['population'][i] /= m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = max(test['population'])\n",
    "# for i in range(test.shape[0]):\n",
    "#     train['population'][i] /= m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Q17'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-411-bbb4e383ab3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# a = [\"age\", 'Q1', 'Q26', 'Q22', 'Q15', 'Q11', ]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Q17'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# print(train[[\"target\",\"age\"]].corr())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4095\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4096\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4097\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4098\u001b[0m         )\n\u001b[1;32m   4099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3913\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3914\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3915\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3917\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3945\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3946\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3947\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3948\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5331\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5332\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5333\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{} not found in axis\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5334\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Q17'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# a = ['population', 'age', 'Q2', 'Q3', 'Q7', 'Q8', 'Q9', 'Q15', 'Q16', 'Q17a', 'Q17b', 'Q20', 'Q24', 'Q25', 'Q26', 'Q27']\n",
    "# a = [\"age\", 'Q1', 'Q26', 'Q22', 'Q15', 'Q11', ]\n",
    "a = ['Q17']\n",
    "train = train.drop(a, axis=1)\n",
    "\n",
    "# print(train[[\"target\",\"age\"]].corr())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Category columns\n",
    "# all_data = train\n",
    "# cat_cols = ['country', 'region', 'owns_mobile'] + [x for x in all_data.columns if x.startswith('Q')]\n",
    "# num_cols = ['age', 'population']\n",
    "# # num_cols = []\n",
    "\n",
    "# # Change columns to their respective datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine train and test set\n",
    "ntrain = train.shape[0] # to be used to split train and test set from the combined dataframe\n",
    "\n",
    "all_data = pd.concat((train, test)).reset_index(drop=True)\n",
    "print(f'The shape of the combined dataframe is: {all_data.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Category columns\n",
    "cat_cols = ['country','region', 'owns_mobile'] + [x for x in all_data.columns if x.startswith('Q')]\n",
    "num_cols = ['age', 'population']\n",
    "\n",
    "# Change columns to their respective datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pearson Correlation\n",
    "# plt.figure(figsize=(12,10))\n",
    "cor = all_data.corr()\n",
    "# sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)\n",
    "# plt.show()\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col = cat_cols + num_cols + ['target']\n",
    "# col.remove('country')\n",
    "# col.remove('region')\n",
    "# tot = []\n",
    "# # print(len(col))\n",
    "# for i in col:\n",
    "#     cor_target = abs(cor[i])\n",
    "#     c = 0\n",
    "#     for j in cor_target:\n",
    "# #         print(c)\n",
    "#         t = col[c]\n",
    "#         if j == 1:\n",
    "#             print(j, t, i)\n",
    "#         if i != t:\n",
    "#             tot.append((j, i, t))\n",
    "#         c += 1\n",
    "# tot.sort(reverse=True)\n",
    "# print(tot[:16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_col = [\"Q7\", \"Q3\", \"Q23\", \"Q2\"]\n",
    "# col = cat_cols + num_cols + ['target']\n",
    "# col.remove('country')\n",
    "# col.remove('region')\n",
    "# for i in new_col:\n",
    "#     tot = []\n",
    "#     cor_target = abs(cor[i])\n",
    "#     c = 0\n",
    "#     for j in cor_target:\n",
    "# #         print(c)\n",
    "#         t = col[c]\n",
    "#         if i != t:\n",
    "#             tot.append((j, i, t))\n",
    "#         c += 1\n",
    "#     tot.sort(reverse=True)\n",
    "#     print(tot[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"Q7\"])\n",
    "# # #Selecting highly correlated features\n",
    "# relevant_features = cor_target[cor_target>0.1]\n",
    "# relevant_features\n",
    "cor_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data[cat_cols] = all_data[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Q10b\n",
    "# # cols = tot[:16]\n",
    "# cols = [ ('Q7', 'Q10a'), ('Q3', 'Q1'), ('Q2', 'Q19'), ('Q23', 'owns_mobile')]\n",
    "# l = all_data.shape[0]\n",
    "# for  b, c in cols:\n",
    "#     for i in range(l):\n",
    "#         if all_data[b][i] == 'nan' and not all_data[c][i] == 'nan' :\n",
    "#             all_data[b][i] = all_data[c][i]\n",
    "# #         if all_data[c][i] == 'nan' and not all_data[b][i] == 'nan' :\n",
    "# #             all_data[c][i] = all_data[b][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in missing values\n",
    "# For cat cols and date cols fill in with mode and for num cols fill in with 9999\n",
    "for col in all_data.columns:\n",
    "  if col in cat_cols:\n",
    "    all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "  elif col in num_cols:\n",
    "    all_data[col] = all_data[col].fillna(all_data[col].mean())\n",
    "\n",
    "# Confirm that there aren't any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Use one hot encoding to turn categorical features to numerical features\n",
    "# Encode categorical features\n",
    "all_data[cat_cols] = all_data[cat_cols].astype('category')\n",
    "all_data = pd.get_dummies(data = all_data, columns = cat_cols)\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Category columns\n",
    "# all_data = test\n",
    "# cat_cols = ['country', 'region', 'owns_mobile'] + [x for x in all_data.columns if x.startswith('Q')]\n",
    "# num_cols = ['age', 'population']\n",
    "\n",
    "# # num_cols = []\n",
    "# # Change columns to their respective datatypes\n",
    "# all_data[cat_cols] = all_data[cat_cols].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fill in missing values\n",
    "# # For cat cols and date cols fill in with mode and for num cols fill in with 9999\n",
    "# for col in all_data.columns:\n",
    "#   if col in cat_cols:\n",
    "#     all_data[col] = all_data[col].fillna(all_data[col].mode()[0])\n",
    "#   elif col in num_cols:\n",
    "#     all_data[col] = all_data[col].fillna(all_data[col].mean())\n",
    "\n",
    "# # Confirm that there aren't any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Use one hot encoding to turn categorical features to numerical features\n",
    "# # Encode categorical features\n",
    "# all_data = pd.get_dummies(data = all_data, columns = cat_cols)\n",
    "# all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test = all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate train and test data from the combined dataframe\n",
    "train_df = all_data[:ntrain]\n",
    "test_df = all_data[ntrain:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select main columns to be used in training\n",
    "main_cols = all_data.columns.difference(['ID', 'target'])\n",
    "# X = train[main_cols]\n",
    "# y = train.target.astype(int)\n",
    "X = train_df[main_cols]\n",
    "y = train_df.target.astype(int)\n",
    "# Split data into train and test sets\n",
    "# ans = []\n",
    "# for i in range(80, 110):\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, random_state=80)\n",
    "\n",
    "#     # Train model\n",
    "#     model = CatBoostRegressor(verbose=0, random_state=i)\n",
    "#     model.fit(X_train, y_train)\n",
    "\n",
    "#     # Make predictions\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     acc = roc_auc_score(y_test, y_pred)\n",
    "#     ans.append((acc, i))\n",
    "#     print(acc, i)\n",
    "# ans.sort()\n",
    "# print(ans)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1, random_state=80)\n",
    "\n",
    "model = CatBoostRegressor(verbose=0)\n",
    "model.fit(X, y)\n",
    "\n",
    "# # Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(f'AUC score on the X_test is: {roc_auc_score(y_test, y_pred)}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "2CY70-KV5lYO",
    "outputId": "a928aaf6-c5c9-4e76-eda1-377e999617a1"
   },
   "outputs": [],
   "source": [
    "# Make prediction on the test set\n",
    "# test = test[main_cols]\n",
    "test_df = test_df[main_cols]\n",
    "# predictions1 = model.predict(test_df)\n",
    "# predictions2 = model2.predict(test_df)\n",
    "\n",
    "# predictions  = (predictions1 + predictions2) / 2.0\n",
    "predictions = model.predict(test_df)\n",
    "# # Create a submission file\n",
    "sub_file = samplesubmission.copy()\n",
    "sub_file.target = predictions\n",
    "\n",
    "# # Check the distribution of your predictions\n",
    "sns.countplot([1 if x >= 0.5 else 0 for x in sub_file.target])\n",
    "plt.title('Predicted Variable Distribution');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "oroCrCK27v-4",
    "outputId": "6de7be09-47f7-41d7-e59e-1c30726c8c3f"
   },
   "outputs": [],
   "source": [
    "# Create a csv file and upload to zindi \n",
    "sub_file.to_csv('Baseline4.csv', index = False)\n",
    "sub_file.head() \n",
    "# i dont know what i am doing, heeeeeeeeeelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Financial_Resilience_Python_StarterNotebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
