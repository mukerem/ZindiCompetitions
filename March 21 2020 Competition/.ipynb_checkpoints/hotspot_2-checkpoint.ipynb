{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"UmojaHack#3:Hotspots/train.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0    1  2\n",
       "0  0  1.0  2\n",
       "1  0  NaN  0\n",
       "2  0  0.0   \n",
       "3  0  1.0  2\n",
       "4  0  1.0  2"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame([range(3), [0, np.NaN, 0], [0, 0, np.NaN], range(3), range(3)])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-cf3d547ceb7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11618\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_agg_by_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11619\u001b[0m         return self._reduce(\n\u001b[0;32m> 11620\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  11621\u001b[0m         )\n\u001b[1;32m  11622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4081\u001b[0m                 )\n\u001b[1;32m   4082\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4083\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4085\u001b[0m         \u001b[0;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36m_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                     \u001b[0;31m# we want to transform an object array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/nanops.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mdtype_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0mthe_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_numeric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype_sum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_sum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ndim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     36\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     37\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "df[2].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>area</th>\n",
       "      <th>date</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>burn_area</th>\n",
       "      <th>climate_aet</th>\n",
       "      <th>climate_def</th>\n",
       "      <th>climate_pdsi</th>\n",
       "      <th>climate_pet</th>\n",
       "      <th>...</th>\n",
       "      <th>landcover_1</th>\n",
       "      <th>landcover_2</th>\n",
       "      <th>landcover_3</th>\n",
       "      <th>landcover_4</th>\n",
       "      <th>landcover_5</th>\n",
       "      <th>landcover_6</th>\n",
       "      <th>landcover_7</th>\n",
       "      <th>landcover_8</th>\n",
       "      <th>population_density</th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8_2000-04-01</td>\n",
       "      <td>8</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>26.771</td>\n",
       "      <td>5.051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1217.142668</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-137.683723</td>\n",
       "      <td>1217.142668</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.455180</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.231987</td>\n",
       "      <td>0.250554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17_2000-04-01</td>\n",
       "      <td>17</td>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>24.107</td>\n",
       "      <td>4.871</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>1285.538959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-299.597339</td>\n",
       "      <td>1285.538959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.662713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.332061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005225</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.876581</td>\n",
       "      <td>0.181754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  area        date     lat    lon  burn_area  climate_aet  \\\n",
       "8    8_2000-04-01     8  2000-04-01  26.771  5.051   0.000000  1217.142668   \n",
       "17  17_2000-04-01    17  2000-04-01  24.107  4.871   0.000615  1285.538959   \n",
       "\n",
       "    climate_def  climate_pdsi  climate_pet  ...  landcover_1  landcover_2  \\\n",
       "8           0.0   -137.683723  1217.142668  ...          0.0     0.455180   \n",
       "17          0.0   -299.597339  1285.538959  ...          0.0     0.662713   \n",
       "\n",
       "    landcover_3  landcover_4  landcover_5  landcover_6  landcover_7  \\\n",
       "8           0.0     0.544820          0.0     0.000000                \n",
       "17          0.0     0.332061          0.0     0.005225                \n",
       "\n",
       "    landcover_8  population_density  precipitation  \n",
       "8           0.0            1.231987       0.250554  \n",
       "17          0.0            2.876581       0.181754  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data['landcover_7'] == '       ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "col = ['ID', 'area', 'date', 'lat', 'lon', 'burn_area', 'climate_aet',\n",
    "       'climate_def', 'climate_pdsi', 'climate_pet', 'climate_pr',\n",
    "       'climate_ro', 'climate_soil', 'climate_srad', 'climate_swe',\n",
    "       'climate_tmmn', 'climate_tmmx', 'climate_vap', 'climate_vpd',\n",
    "       'climate_vs', 'elevation', 'landcover_0', 'landcover_1', 'landcover_2',\n",
    "       'landcover_3', 'landcover_4', 'landcover_5', 'landcover_6',\n",
    "       'landcover_7', 'landcover_8', 'population_density', 'precipitation']\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "s = data.shape[0]\n",
    "for i in range(s):\n",
    "    for j in col:\n",
    "        if(str(data[j][i]).strip() == ''):\n",
    "            data.at[i, j] = ''\n",
    "data.to_csv('train1.csv', index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                        0\n",
       "area                      0\n",
       "date                      0\n",
       "lat                       0\n",
       "lon                       0\n",
       "burn_area                 0\n",
       "climate_aet               0\n",
       "climate_def               0\n",
       "climate_pdsi              0\n",
       "climate_pet               0\n",
       "climate_pr                0\n",
       "climate_ro                0\n",
       "climate_soil              0\n",
       "climate_srad              0\n",
       "climate_swe               0\n",
       "climate_tmmn              0\n",
       "climate_tmmx              0\n",
       "climate_vap               0\n",
       "climate_vpd               0\n",
       "climate_vs                0\n",
       "elevation                 0\n",
       "landcover_0               0\n",
       "landcover_1               0\n",
       "landcover_2               0\n",
       "landcover_3               0\n",
       "landcover_4               0\n",
       "landcover_5               0\n",
       "landcover_6               0\n",
       "landcover_7               2\n",
       "landcover_8               0\n",
       "population_density    19517\n",
       "precipitation             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lat                   float64\n",
       "lon                   float64\n",
       "burn_area             float64\n",
       "climate_aet           float64\n",
       "climate_def           float64\n",
       "climate_pdsi          float64\n",
       "climate_pet           float64\n",
       "climate_pr            float64\n",
       "climate_ro            float64\n",
       "climate_soil          float64\n",
       "climate_srad          float64\n",
       "climate_swe           float64\n",
       "climate_tmmn          float64\n",
       "climate_tmmx          float64\n",
       "climate_vap           float64\n",
       "climate_vpd           float64\n",
       "climate_vs            float64\n",
       "elevation             float64\n",
       "landcover_0           float64\n",
       "landcover_1           float64\n",
       "landcover_2           float64\n",
       "landcover_3           float64\n",
       "landcover_4           float64\n",
       "landcover_5           float64\n",
       "landcover_6           float64\n",
       "landcover_7           float64\n",
       "landcover_8           float64\n",
       "population_density    float64\n",
       "precipitation         float64\n",
       "month                  object\n",
       "year                   object\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['ID', \"area\"], axis = 1)\n",
    "data['month'] = data['date']\n",
    "data['year'] = data['date']\n",
    "data = data.drop('date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s = data.shape[0]\n",
    "for i in range(s):\n",
    "        data.at[i, 'month'] = int(data.at[i, 'month'].split('-')[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(s):\n",
    "        data.at[i, 'year'] = int(data.at[i, 'year'].split('-')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave = data['population_density'].mean()\n",
    "emp = data[data['population_density'].isnull()]\n",
    "a = []\n",
    "for index, row in emp.iterrows():\n",
    "    #a.append(index)\n",
    "    #data = data.drop(a)\n",
    "    data.at[index, 'population_density'] = ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['burn_area']\n",
    "x = data.drop(\"burn_area\", axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.model_selection import KFold, cross_val_score\\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\\nfrom sklearn.tree import DecisionTreeRegressor\\nfrom sklearn.svm import SVR\\nfrom sklearn.neighbors import KNeighborsRegressor\\nfrom sklearn.linear_model import LinearRegression\\nfrom sklearn.metrics import mean_squared_error\\n\\n\\n# Creating a list of regressor algorithms to compare with\\n#\\nmodels = [RandomForestRegressor(), GradientBoostingRegressor(), AdaBoostRegressor(), DecisionTreeRegressor(),          SVR(), KNeighborsRegressor(), LinearRegression()]\\n\\n\\n# Creating lists of the algorithms, to store the accuracy scores of each fold\\n#\\nRandomForest, GradientBoosting, AdaBoost, DecisionTree, SVR, KNeighbors, Linear= ([] for x in range(7))\\n\\n\\n# Creating a list containig the list of each algorithm. Created for easy iteration\\n#\\nmodel_list = [RandomForest, GradientBoosting, AdaBoost, DecisionTree, SVR, KNeighbors, Linear]\\n\\n\\n\\n# Creating a cross validation of 10 folds\\n#\\nkfold  = KFold(n_splits=10, random_state=101)\\n\\n\\n# Iterating through each model and appending the scores of each fold to the appriopriate list\\n#\\nfor i, j in zip(models, model_list):\\n  j.extend(list(cross_val_score(i, X, y, scoring = 'neg_mean_squared_error', cv = kfold)))\\n\\n  \\n# Creating a function to convert neg_mean_squared_error to a square root\\n#\\ndef sq(lis):\\n  new_lis = []\\n  lis = np.array(lis)\\n  for i in lis:\\n    i = np.sqrt(i*-1)\\n    new_lis.append(i)\\n  return new_lis\\n\\n\\n# Creating a dataframe of all the rmses from the iterations for each model\\n#\\nrmses = pd.DataFrame({'Fold': np.arange(1, 11), 'RandomForest': sq(RandomForest), 'GradientBoosting': sq(GradientBoosting), 'Adaboost': sq(AdaBoost), 'DecisionTree': sq(DecisionTree),                       'SVR': sq(SVR), 'Kneighbors': sq(KNeighbors), 'Linear': sq(Linear)})\\n\\n# Setting the index\\n#\\nrmses.set_index('Fold', inplace = True)\\n\\n\\n# Calculating the mean and standard deviation rmse of each algorithm\\n#\\nrmses.loc['mean'] = rmses.mean()\\nrmses.loc['std'] = rmses.std()\\n\\n\\n# Previewing the rmses dataframe\\n#\\nrmses\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# Using different models to find the optimal model\n",
    "#\n",
    "'''\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Creating a list of regressor algorithms to compare with\n",
    "#\n",
    "models = [RandomForestRegressor(), GradientBoostingRegressor(), AdaBoostRegressor(), DecisionTreeRegressor(),\\\n",
    "          SVR(), KNeighborsRegressor(), LinearRegression()]\n",
    "\n",
    "\n",
    "# Creating lists of the algorithms, to store the accuracy scores of each fold\n",
    "#\n",
    "RandomForest, GradientBoosting, AdaBoost, DecisionTree, SVR, KNeighbors, Linear= ([] for x in range(7))\n",
    "\n",
    "\n",
    "# Creating a list containig the list of each algorithm. Created for easy iteration\n",
    "#\n",
    "model_list = [RandomForest, GradientBoosting, AdaBoost, DecisionTree, SVR, KNeighbors, Linear]\n",
    "\n",
    "\n",
    "\n",
    "# Creating a cross validation of 10 folds\n",
    "#\n",
    "kfold  = KFold(n_splits=10, random_state=101)\n",
    "\n",
    "\n",
    "# Iterating through each model and appending the scores of each fold to the appriopriate list\n",
    "#\n",
    "for i, j in zip(models, model_list):\n",
    "  j.extend(list(cross_val_score(i, X, y, scoring = 'neg_mean_squared_error', cv = kfold)))\n",
    "\n",
    "  \n",
    "# Creating a function to convert neg_mean_squared_error to a square root\n",
    "#\n",
    "def sq(lis):\n",
    "  new_lis = []\n",
    "  lis = np.array(lis)\n",
    "  for i in lis:\n",
    "    i = np.sqrt(i*-1)\n",
    "    new_lis.append(i)\n",
    "  return new_lis\n",
    "\n",
    "\n",
    "# Creating a dataframe of all the rmses from the iterations for each model\n",
    "#\n",
    "rmses = pd.DataFrame({'Fold': np.arange(1, 11), 'RandomForest': sq(RandomForest), 'GradientBoosting': sq(GradientBoosting), 'Adaboost': sq(AdaBoost), 'DecisionTree': sq(DecisionTree),\\\n",
    "                       'SVR': sq(SVR), 'Kneighbors': sq(KNeighbors), 'Linear': sq(Linear)})\n",
    "\n",
    "# Setting the index\n",
    "#\n",
    "rmses.set_index('Fold', inplace = True)\n",
    "\n",
    "\n",
    "# Calculating the mean and standard deviation rmse of each algorithm\n",
    "#\n",
    "rmses.loc['mean'] = rmses.mean()\n",
    "rmses.loc['std'] = rmses.std()\n",
    "\n",
    "\n",
    "# Previewing the rmses dataframe\n",
    "#\n",
    "rmses\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"UmojaHack#3:Hotspots/test.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave = test['population_density'].mean()\n",
    "emp = test[test['population_density'].isnull()]\n",
    "for index, row in emp.iterrows():\n",
    "    test.at[index, 'population_density'] = ave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['month'] = test['date']\n",
    "test['year'] = test['date']\n",
    "test = test.drop('date', axis=1)\n",
    "s = test.shape[0]\n",
    "for i in range(s):\n",
    "        test.at[i, 'month'] = int(test.at[i, 'month'].split('-')[1])\n",
    "for i in range(s):\n",
    "        test.at[i, 'year'] = int(test.at[i, 'year'].split('-')[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = test.drop(['area', 'ID', 'burn_area'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Import the necessary libraries first\n",
    "# from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import chi2, f_regression\n",
    "\n",
    "\n",
    "# # Feature extraction\n",
    "# test1 = SelectKBest(score_func=f_regression, k=16)\n",
    "# fit = test1.fit(x, y)\n",
    "\n",
    "# # Summarize scores\n",
    "# np.set_printoptions(precision=3)\n",
    "# print(fit.scores_)\n",
    "\n",
    "# features = fit.transform(x)\n",
    "# # Summarize selected features\n",
    "# print(features[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = [float(i) for i in \"\"\"5.130e+02 1.247e+05 1.492e+05 5.049e+04 6.953e+04 1.726e+04 1.433e+04\n",
    " 2.637e+04 1.112e-01 8.256e+04 5.245e+03 1.293e+05 1.145e+05 5.587e+04\n",
    " 1.246e+04 3.481e+02 1.545e+02 4.972e+04 4.428e+00 5.577e+04 2.329e+02\n",
    " 7.798e+01 1.285e+02 1.223e+01 4.341e+01 6.507e+04\"\"\".split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lat', 'lon', 'climate_aet', 'climate_def', 'climate_pdsi',\n",
       "       'climate_pet', 'climate_pr', 'climate_ro', 'climate_soil',\n",
       "       'climate_srad', 'climate_swe', 'climate_tmmn', 'climate_tmmx',\n",
       "       'climate_vap', 'climate_vpd', 'climate_vs', 'elevation', 'landcover_0',\n",
       "       'landcover_1', 'landcover_2', 'landcover_3', 'landcover_4',\n",
       "       'landcover_5', 'landcover_6', 'landcover_7', 'landcover_8',\n",
       "       'population_density', 'precipitation', 'month', 'year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = x.columns\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(149200.0, 'climate_def'),\n",
       " (129300.0, 'climate_vap'),\n",
       " (124700.0, 'climate_aet'),\n",
       " (114500.0, 'climate_vpd'),\n",
       " (82560.0, 'climate_tmmn'),\n",
       " (69530.0, 'climate_pr'),\n",
       " (65070.0, 'precipitation'),\n",
       " (55870.0, 'climate_vs'),\n",
       " (55770.0, 'landcover_4'),\n",
       " (50490.0, 'climate_pet'),\n",
       " (49720.0, 'landcover_2'),\n",
       " (26370.0, 'climate_srad'),\n",
       " (17260.0, 'climate_ro'),\n",
       " (14330.0, 'climate_soil'),\n",
       " (12460.0, 'elevation'),\n",
       " (5245.0, 'climate_tmmx'),\n",
       " (513.0, 'lat'),\n",
       " (348.1, 'landcover_0'),\n",
       " (232.9, 'landcover_5'),\n",
       " (154.5, 'landcover_1'),\n",
       " (128.5, 'landcover_7'),\n",
       " (77.98, 'landcover_6'),\n",
       " (43.41, 'population_density'),\n",
       " (12.23, 'landcover_8'),\n",
       " (4.428, 'landcover_3'),\n",
       " (0.1112, 'climate_swe')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = ['lat', 'climate_aet', 'climate_def', 'climate_pet', 'climate_pr',\n",
    "       'climate_ro', 'climate_soil', 'climate_srad', 'climate_swe',\n",
    "       'climate_tmmn', 'climate_tmmx', 'climate_vap', 'climate_vpd',\n",
    "       'climate_vs', 'elevation', 'landcover_0', 'landcover_1', 'landcover_2',\n",
    "       'landcover_3', 'landcover_4', 'landcover_5', 'landcover_6',\n",
    "       'landcover_7', 'landcover_8', 'population_density', 'precipitation']\n",
    "abc = [(i, j) for i,j in zip(ab,f)]\n",
    "abc.sort(reverse = True)\n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['landcover_3', 'climate_swe']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_col = [j for i, j in abc[-2: ]]\n",
    "#drop_col.remove('lat')\n",
    "drop_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = sub.drop(drop_col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the top three models; XGBoost, Catboost and Gradientboost to train and make predictions\n",
    "# Creating a list of models to use\n",
    "models = [RandomForestRegressor()]\n",
    "model_names = ['random3']\n",
    "\n",
    "\n",
    "# Using a for loop to create a submission file for each model\n",
    "#\n",
    "for model, model_name in zip(models, model_names):\n",
    "  regressor = model                      # instantiating the model\n",
    "  regressor.fit(x, y)                    # Training the model\n",
    "  predictions  = regressor.predict(sub)  # Making predictions\n",
    "  submission_df = pd.DataFrame({'ID': test.ID, 'burn_area': predictions}) # Creating a submission file\n",
    "  submission_df.to_csv(model_name + '_baseline.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = ['lat', 'lon', 'climate_aet', 'climate_def', 'climate_pdsi',\n",
    "       'climate_pet', 'climate_pr', 'climate_ro', 'climate_soil',\n",
    "       'climate_srad', 'climate_swe', 'climate_tmmn', 'climate_tmmx',\n",
    "       'climate_vap', 'climate_vpd', 'climate_vs', 'elevation', 'landcover_0',\n",
    "       'landcover_1', 'landcover_2', 'landcover_3', 'landcover_4',\n",
    "       'landcover_5', 'landcover_6', 'landcover_7', 'landcover_8',\n",
    "       'population_density', 'precipitation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>burn_area</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_2014-01-01</td>\n",
       "      <td>0.088133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1_2014-01-01</td>\n",
       "      <td>0.085796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2_2014-01-01</td>\n",
       "      <td>0.116526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3_2014-01-01</td>\n",
       "      <td>0.136310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4_2014-01-01</td>\n",
       "      <td>0.142671</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID  burn_area\n",
       "0  0_2014-01-01   0.088133\n",
       "1  1_2014-01-01   0.085796\n",
       "2  2_2014-01-01   0.116526\n",
       "3  3_2014-01-01   0.136310\n",
       "4  4_2014-01-01   0.142671"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targeted = pd.read_csv(\"random3_baseline.csv\")\n",
    "targeted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
